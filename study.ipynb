{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c0a715",
   "metadata": {},
   "source": [
    "# Dataset and Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b61eff",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset titled \"Letter Recognition Data Set\" contains 20,000 instances of distorted uppercase English letters from 20 different fonts. The dataset has 17 features, consisting of 1 categorical string value and 16 numerical values, which describe the pixel image of each letter instance. Such features include: width & height of the box, vert. and horiz. position of the box, number of 'on' pixels (like in a binary image), etc.\n",
    "\n",
    "I chose this dataset because it is related to types of machine learning problems that are becoming increasingly more prevalent nowadays. Examples of problems include identifying symbols in engineering blueprints or identifing vehicles in traffic camera footage.\n",
    "\n",
    "The purpose of this study is to use this data to build a predictive model capable of discerning letters from a given set of features.\n",
    "\n",
    "### Source\n",
    "Obtained from the UCI repository at https://archive.ics.uci.edu/ml/datasets/Letter+Recognition (accessed 22th Oct, 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18c371",
   "metadata": {},
   "source": [
    "## Literature Review\n",
    "To gain insight into an actual machine learning problem, I selected a peer-reviewed paper to discuss. This paper is relevant because it tackles a similar classification problem of letter identification. I had originally intended to review the [**original paper**](https://link.springer.com/article/10.1007/BF00114162) the dataset was constructed for; however, the techniques present within are long out of date since being published in 1991.\n",
    "\n",
    "### Review\n",
    "B. B. Yousif et al in “Toward an ONKM-AVLPR” present a more effective methodology of license plate recognition. The authors describe each step of their new method and compare their results with those of older methods in order to prove the method’s effectiveness. The main motivation for developing a new method was to overcome a challenge faced by previous methods: image degradations. Degradations included shadows on the license plate or faded or otherwise unclear lettering and tended to affect the overall performance (accuracy) of the results. The data used in this study comprise photographs of Egyptian and Croatian license plates taken under different lighting conditions.\n",
    "\n",
    "The method firstly preprocesses the images in order to locate the license plate and improve overall performance. Preprocessing operations include resizing, greyscaling and contrasting. Following this, a neutrosophic set algorithm is used to reduce indeterminacy in the data and is optimised with a genetic algorithm to improve accuracy. Next, a k-means algorithm is used to cluster the data. Then, connected-components labeling analysis takes place to label the characters. Finally, statistical cross correlation is used to match the characters against templates in a database. The authors provide flowcharts to give a high-level overview of each algorithm. They also use tables of images to illustrate how an image evolves through each step of the method.\n",
    "\n",
    "The authors provide tables of performance metrics to show how different factors affect accuracy. One important factor was optimising the neutrosophic set as it improved the results tremendously when applied. Afterwards, the authors do a comparative study, highlighting the differences between their method’s output to those of older methods. For example, older methods produced grainy images and some failed completely to locate characters. The comparison demonstrates the new method is most effective.\n",
    "\n",
    "The paper is quite technical, as it predominantly speaks in jargon. The use of flowcharts and tables aid understanding and are nicely presented tables. They clearly evidenced their method to be more performant than older methods of recognition. Overall, it is well made and very accessible.\n",
    "\n",
    "### Citation\n",
    "B. B. Yousif, M. M. Ata, N. Fawzy and M. Obaya, \"Toward an Optimized Neutrosophic k-Means With Genetic Algorithm for Automatic Vehicle License Plate Recognition (ONKM-AVLPR),\" in IEEE Access, vol. 8, pp. 49285-49312, 2020, doi: 10.1109/ACCESS.2020.2979185.\n",
    "\n",
    "Obtained from https://ieeexplore.ieee.org/document/9027882 (accessed 23rd Oct, 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432836b4",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "It is important to explore our data to gain a better insight into it, which helps us later in the preprocessing stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6622156",
   "metadata": {},
   "source": [
    "### Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fc1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/letter-recognition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae1ea8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lettr</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lettr  x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0     T      2      8      3     5      1      8     13      0      6      6   \n",
       "1     I      5     12      3     7      2     10      5      5      4     13   \n",
       "2     D      4     11      6     8      6     10      6      2      6     10   \n",
       "3     N      7     11      6     6      3      5      9      4      6      4   \n",
       "\n",
       "   x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0     10      8      0      8      0      8  \n",
       "1      3      9      2      8      4     10  \n",
       "2      3      7      3      7      3      9  \n",
       "3      4     10      6     10      2      8  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print some rows\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc4309",
   "metadata": {},
   "source": [
    "### Data Size and Feature Types\n",
    "We can get a basic overview of the dataset with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07135764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 20000\tColumns: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lettr    object\n",
       "x-box     int64\n",
       "y-box     int64\n",
       "width     int64\n",
       "high      int64\n",
       "onpix     int64\n",
       "x-bar     int64\n",
       "y-bar     int64\n",
       "x2bar     int64\n",
       "y2bar     int64\n",
       "xybar     int64\n",
       "x2ybr     int64\n",
       "xy2br     int64\n",
       "x-ege     int64\n",
       "xegvy     int64\n",
       "y-ege     int64\n",
       "yegvx     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dimensions\n",
    "print(f'Rows: {df.shape[0]}\\tColumns: {df.shape[1]}')\n",
    "\n",
    "# Show data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc0fca",
   "metadata": {},
   "source": [
    "Listed above are the name and type of each feature. The features consist of 1 categorical value and 16 numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95da4e",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "**lettr** is a categorical attribute that states which of the 26 letters an instance is describing. By getting the class distribution, we can assess the balance of this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46815821",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are **26** different letters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>789</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>766</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>736</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>805</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>768</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>775</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>773</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>734</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>755</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>747</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>739</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>761</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>792</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>783</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>753</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>803</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>783</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>758</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>748</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>796</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>813</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>764</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>752</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>787</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>786</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>734</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count  Proportion\n",
       "A    789        3.94\n",
       "B    766        3.83\n",
       "C    736        3.68\n",
       "D    805        4.03\n",
       "E    768        3.84\n",
       "F    775        3.88\n",
       "G    773        3.86\n",
       "H    734        3.67\n",
       "I    755        3.77\n",
       "J    747        3.74\n",
       "K    739        3.69\n",
       "L    761        3.81\n",
       "M    792        3.96\n",
       "N    783        3.91\n",
       "O    753        3.77\n",
       "P    803        4.01\n",
       "Q    783        3.91\n",
       "R    758        3.79\n",
       "S    748        3.74\n",
       "T    796        3.98\n",
       "U    813        4.06\n",
       "V    764        3.82\n",
       "W    752        3.76\n",
       "X    787        3.94\n",
       "Y    786        3.93\n",
       "Z    734        3.67"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = df['lettr']\n",
    "letters_dist = pd.DataFrame({ 'Count': letters.value_counts() }).sort_index()\n",
    "proportions = []\n",
    "\n",
    "for l in letters_dist['Count']:\n",
    "    p = round(l / letters.shape[0] * 100, 2)\n",
    "    proportions.append(p)\n",
    "\n",
    "# Count unique values\n",
    "unique = len(letters.unique())\n",
    "print(f'There are **{unique}** different letters.')\n",
    "\n",
    "letters_dist['Proportion'] = proportions\n",
    "letters_dist.head(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a157b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average proportion: 3.8458%\n",
      "Actual proportion: 3.8462%\n"
     ]
    }
   ],
   "source": [
    "print(f'Average proportion: {round(sum(proportions) / 26, 4)}%')\n",
    "print(f'Actual proportion: {round(1/26*100, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f1807",
   "metadata": {},
   "source": [
    "The above shows the count and proportions for each letter. Also, average and actual proportions have been calculated to check how balanced the dataset is. As we can see, the calculated average is about the same as the actual, suggesting the dataset is quite balanced. To further visualise this, we can use a barplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3bd0eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(style='whitegrid')\n",
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "plt.hist(letters.sort_values(0), bins=51)\n",
    "plt.title('Distribution of Letters')\n",
    "plt.xlabel('Letters')\n",
    "plt.ylabel('Instances')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef469c",
   "metadata": {},
   "source": [
    "Again, we can see the distribution is quite balanced. Having an imbalance means a model trained on that data would become lopsided and likely make mistakes in its predictions, due to the underrepresentation of some letters. Therefore, having a balanced dataset means a model would learn each letter fairly equally, improving its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1f4f1",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "We can check for gaps in our data with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681d7cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lettr    0\n",
       "x-box    0\n",
       "y-box    0\n",
       "width    0\n",
       "high     0\n",
       "onpix    0\n",
       "x-bar    0\n",
       "y-bar    0\n",
       "x2bar    0\n",
       "y2bar    0\n",
       "xybar    0\n",
       "x2ybr    0\n",
       "xy2br    0\n",
       "x-ege    0\n",
       "xegvy    0\n",
       "y-ege    0\n",
       "yegvx    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0850543",
   "metadata": {},
   "source": [
    "The output shows zero for each feature, meaning there are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bdc6ef",
   "metadata": {},
   "source": [
    "### Outliers and Correlations\n",
    "It is possible that some data is drastically different. We can get a statistical overview of the data with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b08bc48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x-box         y-box         width         high         onpix  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "              x-bar         y-bar         x2bar         y2bar         xybar  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "             x2ybr         xy2br         x-ege         xegvy         y-ege  \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "             yegvx  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54c316",
   "metadata": {},
   "source": [
    "The above shows a consistently low standard deviation, suggesting the data is clustered fairly closely around the mean. Also note that the min and max values are 0 and 15 across all columns.\n",
    "\n",
    "We can display some of these features as graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a037203",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(style='darkgrid')\n",
    "\n",
    "# Select specific columns\n",
    "columns = ['width', 'high', 'x2bar', 'y2bar']\n",
    "selection = df[columns]\n",
    "\n",
    "selection.hist(bins=31,figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40a304",
   "metadata": {},
   "source": [
    "Plotted above are the width, height, x2bar and y2bar. The x2bar is defined as the mean x variance and the y2bar as the mean y variance. When we pair the x2bar with the width and the y2bar with the height (labeled high), we can see two very similar pairs of graphs, suggesting a correlation between them.\n",
    "\n",
    "The x2bar suggests that wider letters have more variance and vice versa. Similarly, y2bar suggests taller letters have more variance.\n",
    "\n",
    "We can calculate the correlations between these columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f70a7a67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>-0.098611</td>\n",
       "      <td>0.057074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.660215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082383</td>\n",
       "      <td>0.059032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2bar</th>\n",
       "      <td>-0.098611</td>\n",
       "      <td>0.082383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.188431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y2bar</th>\n",
       "      <td>0.057074</td>\n",
       "      <td>0.059032</td>\n",
       "      <td>-0.188431</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          width      high     x2bar     y2bar\n",
       "width  1.000000  0.660215 -0.098611  0.057074\n",
       "high   0.660215  1.000000  0.082383  0.059032\n",
       "x2bar -0.098611  0.082383  1.000000 -0.188431\n",
       "y2bar  0.057074  0.059032 -0.188431  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection.corr()[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bc7f8",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In this stage, we will prepare our dataset for model training. As we learned from exploring the data, the dataset is fairly balanced and there is no missing data, meaning it is not necessary to take any extra steps to fix them.\n",
    "\n",
    "Were there an imbalance, some form of data sampling would be required. Likewise, were there any missing data, we would need to use a technique like filling the gaps with the mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c74469",
   "metadata": {},
   "source": [
    "### Split Features and Encode Labels\n",
    "We firstly need to separate the input features from the target variable (or label). It is also good practice to encode our categorical labels into integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc6eee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['T' 'I' 'D' 'N' 'G' 'S' 'B' 'A']\n",
      "After:  [19  8  3 13  6 18  1  0]\n"
     ]
    }
   ],
   "source": [
    "# Store input features\n",
    "# Using numpy array is better (also to match label format)\n",
    "X = np.array(df.drop('lettr', axis=1))\n",
    "\n",
    "# Store & Encode Labels\n",
    "Y = df['lettr']\n",
    "Y = LabelEncoder().fit(Y).transform(Y) # returns numpy array\n",
    "\n",
    "# Show encoded values:\n",
    "print(f'Before: {np.array(df[\"lettr\"][:8])}')\n",
    "print(f'After:  {Y[:8]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af679d65",
   "metadata": {},
   "source": [
    "### Test and Train Data\n",
    "Next, we need to divide our dataset into training and test sets. `train_size` has been set to use 80% of the total instances (16,000 rows) for training.\n",
    "\n",
    "We also set the random state to control the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f9e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random state\n",
    "r_state = 20\n",
    "\n",
    "# Get our test and train data\n",
    "X_train, X_test, Y_train, Y_test = tts(X, Y, train_size=.8, random_state=r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28142e94",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "In order to reduce noise, we can use min-max normalisation to scale the numerical values down to a range of 0 to 1. As noted earlier, the input features have common min and max values (0 and 15), so normalisation is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802b6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 15.0\n",
    "X_test = X_test / 15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936efc01",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "For this study, I have chosen to use a Random Forests model. Random Forests make classifications by selecting the most frequent class from an ensemble of decision trees. Given the variety of features in my dataset, I believe this type of model is befitting and would yield accurate results because it would classify a letter based on multiple decisions.\n",
    "\n",
    "## Model\n",
    "### Build and Train\n",
    "\n",
    "We will use the `RandomForestClassifier` class provided by scikit-learn.\n",
    "\n",
    "We specify the number of trees with `n_estimators`. We'll set a reasonable value to begin with and see how the model performs. Next, the number of features to consider is defined by `max_features`. Setting this to `None` uses the number of features available (i.e. 16). Finally, we control the randomness with `random_state`, allowing us to produce consistent results. We'll simply resuse the `r_state` value set earlier.\n",
    "\n",
    "After the instance is created, we'll train our model by fitting the **X_train** and **Y_train** sets created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5d0822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=None, n_estimators=150, random_state=20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=150, max_features=None, random_state=r_state)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba46861",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "Once trained, we can use the model to make predictions. The following code shows our model making class predictions on the **X_test** set. It also predicts the class probabilities for the same set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "270493a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & Probabilities\n",
    "prediction = model.predict(X_test)\n",
    "probability = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c923eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for 1st instance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.01333333, 0.        , 0.        ,\n",
       "        0.        , 0.00666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.96      ,\n",
       "        0.00666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Probabilities for 1st instance:')\n",
    "probability[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7971b4",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "The `sklearn.metrics` module provides functions to evaluate our model's quality of performance, such as calculating metrics and printing reports. Reviewing these will inform us if there is any fine tuning to be done to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d53d6",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "We can use accuracy_score to calculate the accuracy of the model's results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0c22d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End result accuracy score is: 93.42%\n"
     ]
    }
   ],
   "source": [
    "model_accuracy = accuracy_score(Y_test, prediction)\n",
    "print(f'End result accuracy score is: {np.round(model_accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6463d",
   "metadata": {},
   "source": [
    "As shown, the model, with its current settings, performs with more than 93% accuracy. This could be due to the number of estimators (decision trees) we set, or it could be the number of rows given to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87aeb7",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "We can build a classification report to see exactly how the model performed for each letter. This report displays the precision, recall and f1-score for each class label.\n",
    "\n",
    "Note the indices of 0–25 are the encoded labels for A–Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d100060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.977636</td>\n",
       "      <td>156.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.909699</td>\n",
       "      <td>147.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>159.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>149.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.928994</td>\n",
       "      <td>0.912791</td>\n",
       "      <td>0.920821</td>\n",
       "      <td>172.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>148.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.889655</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>145.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.875399</td>\n",
       "      <td>153.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>126.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>154.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.937008</td>\n",
       "      <td>0.908397</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>131.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>144.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>148.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>169.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>155.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>182.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.951807</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.938356</td>\n",
       "      <td>0.919463</td>\n",
       "      <td>146.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.926380</td>\n",
       "      <td>0.949686</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>159.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>148.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.957055</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>165.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>151.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.968641</td>\n",
       "      <td>144.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.935294</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>170.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.951140</td>\n",
       "      <td>151.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>155.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.934250</td>\n",
       "      <td>0.934250</td>\n",
       "      <td>0.934250</td>\n",
       "      <td>0.93425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.934665</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>0.934275</td>\n",
       "      <td>4000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.934803</td>\n",
       "      <td>0.934250</td>\n",
       "      <td>0.934313</td>\n",
       "      <td>4000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.974522  0.980769  0.977636   156.00000\n",
       "1              0.894737  0.925170  0.909699   147.00000\n",
       "2              0.948387  0.924528  0.936306   159.00000\n",
       "3              0.894040  0.906040  0.900000   149.00000\n",
       "4              0.928994  0.912791  0.920821   172.00000\n",
       "5              0.906667  0.918919  0.912752   148.00000\n",
       "6              0.955556  0.889655  0.921429   145.00000\n",
       "7              0.856250  0.895425  0.875399   153.00000\n",
       "8              0.952756  0.960317  0.956522   126.00000\n",
       "9              0.965035  0.896104  0.929293   154.00000\n",
       "10             0.937008  0.908397  0.922481   131.00000\n",
       "11             0.944444  0.944444  0.944444   144.00000\n",
       "12             0.958904  0.945946  0.952381   148.00000\n",
       "13             0.952663  0.952663  0.952663   169.00000\n",
       "14             0.893750  0.922581  0.907937   155.00000\n",
       "15             0.929348  0.939560  0.934426   182.00000\n",
       "16             0.951807  0.913295  0.932153   173.00000\n",
       "17             0.901316  0.938356  0.919463   146.00000\n",
       "18             0.926380  0.949686  0.937888   159.00000\n",
       "19             0.922078  0.959459  0.940397   148.00000\n",
       "20             0.957055  0.945455  0.951220   165.00000\n",
       "21             0.940397  0.940397  0.940397   151.00000\n",
       "22             0.972028  0.965278  0.968641   144.00000\n",
       "23             0.946429  0.935294  0.940828   170.00000\n",
       "24             0.935897  0.966887  0.951140   151.00000\n",
       "25             0.954839  0.954839  0.954839   155.00000\n",
       "accuracy       0.934250  0.934250  0.934250     0.93425\n",
       "macro avg      0.934665  0.934318  0.934275  4000.00000\n",
       "weighted avg   0.934803  0.934250  0.934313  4000.00000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Report & Wrap with DataFrame\n",
    "report_dict = classification_report(Y_test, prediction, output_dict=True)\n",
    "report = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Output report\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b2714",
   "metadata": {},
   "source": [
    "This shows all classes with an f1-score of 90% or above. This tells us the model did not favour any classes in particular and made balanced predictions. If we recall the data exploration, this was expected due the balanced distribution.\n",
    "\n",
    "However, some classes had a **precision** of less than 90%. We can display those classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d67606d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels (order of appearance):  ['B', 'D', 'H', 'O']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.909699</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.875399</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision    recall  f1-score  support\n",
       "1    0.894737  0.925170  0.909699    147.0\n",
       "3    0.894040  0.906040  0.900000    149.0\n",
       "7    0.856250  0.895425  0.875399    153.0\n",
       "14   0.893750  0.922581  0.907937    155.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode indices back to letters\n",
    "def decode(n):\n",
    "    return chr(int(n)+65)\n",
    "\n",
    "def decode_values(values):\n",
    "    return [decode(n) for n in values]\n",
    "\n",
    "# Grab precision < 90%\n",
    "less_than_90 = report[report['precision'] < 0.9]\n",
    "\n",
    "# Output\n",
    "print(f'Labels (order of appearance):  {decode_values(list(less_than_90.index.values))}')\n",
    "less_than_90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85fa05",
   "metadata": {},
   "source": [
    "Above shows the values for the letters B, D, H and O. The lowest value was H with 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904bb4b4",
   "metadata": {},
   "source": [
    "### Misclassifications\n",
    "We can also manually check which instances the model failed to make a correct classification on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69da712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified **263** instances (1.31% error)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted  actual\n",
       "23          12      20\n",
       "58          20       9\n",
       "82          17      10\n",
       "91           3      10\n",
       "103          7      23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({ 'predicted': prediction, 'actual': Y_test })\n",
    "# results['probability'] = probability\n",
    "incorrect = results[results.predicted != results.actual]\n",
    "\n",
    "print(f'Misclassified **{incorrect.shape[0]}** instances ({round(incorrect.shape[0]/df.shape[0] * 100, 2)}% error)')\n",
    "incorrect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b33c8",
   "metadata": {},
   "source": [
    "Furthermore, we can list the most frequent miscounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "888e097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`O` was mistaken for `Q` 6 times\n",
      "`H` was mistaken for `D` 6 times\n",
      "`H` was mistaken for `K` 5 times\n",
      "`F` was mistaken for `P` 5 times\n",
      "`R` was mistaken for `H` 5 times\n",
      "`P` was mistaken for `F` 5 times\n",
      "`D` was mistaken for `H` 4 times\n",
      "`C` was mistaken for `G` 4 times\n",
      "`V` was mistaken for `B` 4 times\n",
      "`T` was mistaken for `Y` 3 times\n"
     ]
    }
   ],
   "source": [
    "# Count incorrect instances\n",
    "miscounts = pd.DataFrame(incorrect.groupby(['predicted', 'actual']).size()).reset_index()\n",
    "\n",
    "# Rename columns, sort df and slice top 10 rows\n",
    "miscounts.columns = ['predicted', 'actual', 'count']\n",
    "miscounts = miscounts.sort_values('count', ascending=False)[:10]\n",
    "\n",
    "# Decode each letter and show count\n",
    "for index, row in miscounts.iterrows():\n",
    "    print(f'`{decode(row[0])}` was mistaken for `{decode(row[1])}` {row[2]} times')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d2ca1",
   "metadata": {},
   "source": [
    "The above shows the model frequently mistakes `O` with `Q` which is understandable because they are very similar in shape. Other examples of similar shapes include:\n",
    "- `P` with `F`\n",
    "- `F` with `P`\n",
    "- `C` with `G`\n",
    "- `T` with `Y`\n",
    "\n",
    "Naturally, across these instances, there are some pairs, where the model mistakes a letter for another specific letter and vice versa, as is the case with `H` and `D` as well as `P` and `F`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3198c",
   "metadata": {},
   "source": [
    "### Importance\n",
    "To get more insight into the model's decision-making, we can calculate the importance of each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "378800ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>x-ege</td>\n",
       "      <td>0.136424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>y-ege</td>\n",
       "      <td>0.112096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>y2bar</td>\n",
       "      <td>0.109859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xegvy</td>\n",
       "      <td>0.097744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xy2br</td>\n",
       "      <td>0.086163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>x2ybr</td>\n",
       "      <td>0.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xybar</td>\n",
       "      <td>0.071428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x2bar</td>\n",
       "      <td>0.069406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>y-bar</td>\n",
       "      <td>0.058311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yegvx</td>\n",
       "      <td>0.056154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x-bar</td>\n",
       "      <td>0.046812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>onpix</td>\n",
       "      <td>0.018814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y-box</td>\n",
       "      <td>0.017795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0.014931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x-box</td>\n",
       "      <td>0.013475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>width</td>\n",
       "      <td>0.010290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  importance\n",
       "12   x-ege    0.136424\n",
       "14   y-ege    0.112096\n",
       "8    y2bar    0.109859\n",
       "13   xegvy    0.097744\n",
       "11   xy2br    0.086163\n",
       "10   x2ybr    0.080300\n",
       "9    xybar    0.071428\n",
       "7    x2bar    0.069406\n",
       "6    y-bar    0.058311\n",
       "15   yegvx    0.056154\n",
       "5    x-bar    0.046812\n",
       "4    onpix    0.018814\n",
       "1    y-box    0.017795\n",
       "3     high    0.014931\n",
       "0    x-box    0.013475\n",
       "2    width    0.010290"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = []\n",
    "features = list(df.columns)[1:] # drop the first value since label is unimportant\n",
    "\n",
    "for feature, score in zip(features, model.feature_importances_):\n",
    "    feature_importances.append({ 'feature': feature, 'importance': score })\n",
    "\n",
    "# Sort by importance\n",
    "pd.DataFrame(feature_importances).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a719d45",
   "metadata": {},
   "source": [
    "The table shows that among the least important values are width, height. This is interesting because in most fonts some letters are wider than others - compare W with I - with the obvious exception being monospaced fonts. This perhaps gives some insight into how the distortions affected the letters.\n",
    "\n",
    "On the other hand, the two most important features are x-ege and y-ege, which are the horizontal and vertical mean edge counts respectively. This makes sense because if you compare the letters `E` and `L`, `E` has a higher vertical edge count than `L`. Likewise compare `I` with `W` for horizontal edge count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65623514",
   "metadata": {},
   "source": [
    "# Solution Comparison\n",
    "Our model achieved a very high accuracy result but it would be interesting to see how other models would compare. In this section, we will experiment with a variety of models to see how different input parameters affect the performance of the model.\n",
    "\n",
    "Note the same `random_state` value will be used across all experiments to maintain consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164669a8",
   "metadata": {},
   "source": [
    "## Parameter Tweaking\n",
    "In this experiment, we will observe the effects of tweaking some parameters of the random forest function. The main parameters are `n_estimators`, `max_features` and `random_state`, although the `random_state` will be constant to ensure reproducibility.\n",
    "\n",
    "Several tests will be run:\n",
    "1. Use 50 trees instead of 150\n",
    "2. Use 4 features (quarter features)\n",
    "3. Use 300 trees instead of 150\n",
    "3. Use 8 features (half of features)\n",
    "\n",
    "The following code will run these three tests consecutively, storing each resulting accuracy in a list to be evalutated afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e745a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_state = 20\n",
    "\n",
    "def print_results(lst):\n",
    "    for result in lst:\n",
    "        print(f\"{result['name']} \\t {round(result['accuracy']*100, 2)}% \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8e56d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Test \t 93.42% \n",
      "Test 1 \t 93.72% \n",
      "Test 2 \t 96.68% \n",
      "Test 3 \t 93.52% \n",
      "Test 4 \t 96.3% \n"
     ]
    }
   ],
   "source": [
    "# Contain within function to avoid affecting previous results\n",
    "def experiment_parameter_tweaking():\n",
    "    results = [\n",
    "        { 'name': 'Original Test', 'accuracy': model_accuracy }\n",
    "    ]\n",
    "\n",
    "    tests = [\n",
    "        RandomForestClassifier(n_estimators=50,  max_features=None, random_state=r_state),\n",
    "        RandomForestClassifier(n_estimators=150, max_features=4,    random_state=r_state),\n",
    "        RandomForestClassifier(n_estimators=300, max_features=None, random_state=r_state),\n",
    "        RandomForestClassifier(n_estimators=150, max_features=8,    random_state=r_state),\n",
    "    ]\n",
    "\n",
    "    # Split sets & normalise\n",
    "    X_train, X_test, Y_train, Y_test = tts(X, Y, train_size=.8, random_state=r_state)\n",
    "    X_train = X_train / 15.0 ; X_test = X_test / 15.0\n",
    "\n",
    "    # Run tests\n",
    "    index = 1\n",
    "    for test in tests:\n",
    "        # Fit model\n",
    "        test.fit(X_train, Y_train)\n",
    "\n",
    "        # Prediction\n",
    "        yhat = test.predict(X_test)\n",
    "        acc  = accuracy_score(Y_test, yhat)\n",
    "\n",
    "        # Store prediction\n",
    "        results.append({ 'name': f'Test {index}', 'accuracy': acc })\n",
    "        index += 1\n",
    "\n",
    "    # Print\n",
    "    print_results(results)\n",
    "\n",
    "experiment_parameter_tweaking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4b853",
   "metadata": {},
   "source": [
    "All tests achieved a higher accuracy than the original model. The two best results are from test 2 and 4, where the primary change was the `max_feature`. Test 2 set a value of 4 which yielded the best result, showing that less features squeezes a little more performance out.\n",
    "\n",
    "Tests 1 and 3 changed the `n_estimators` and, interestingly, setting a lower value yielded a better result. This suggests that having more estimators makes the model slightly more prone to misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50739ca6",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "For the initial model, the train_test_split method used a value of 0.8 for the `train_size` parameter. This means there was a 80/20 divide on training and testing sets. For this experiment, a range of values from 0.5 to 0.7 will be testsed - i.e. 50–70%. The original settings are the same (estimators and max features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7df17fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Test \t 93.42% \n",
      "Partition test \t 93.63% \n",
      "Partition test \t 93.48% \n",
      "Partition test \t 92.48% \n"
     ]
    }
   ],
   "source": [
    "def experiment_partitioning(X, Y):\n",
    "    results = [\n",
    "        { 'name': 'Original Test', 'accuracy': model_accuracy }\n",
    "    ]\n",
    "\n",
    "    exp_model = RandomForestClassifier(n_estimators=150, max_features=None, random_state=r_state)\n",
    "\n",
    "    sizes = [0.7, 0.6, 0.5]\n",
    "\n",
    "    for size in sizes:\n",
    "        # Split sets & normalise\n",
    "        X_train, X_test, Y_train, Y_test = tts(X, Y, train_size=size, random_state=r_state)\n",
    "        X_train = X_train / 15.0 ; X_test = X_test / 15.0\n",
    "\n",
    "        # Fit model\n",
    "        exp_model.fit(X_train, Y_train)\n",
    "\n",
    "        # Make prediction\n",
    "        yhat = exp_model.predict(X_test)\n",
    "        acc = accuracy_score(Y_test, yhat)\n",
    "        results.append({ 'name': 'Partition test', 'accuracy': acc })\n",
    "\n",
    "    # Print\n",
    "    print_results(results)\n",
    "\n",
    "experiment_partitioning(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5a173",
   "metadata": {},
   "source": [
    "As expected, the 50/50 split has the lowest accuracy with 92.48%. However, interestingly, the 60/40 and 70/30 divisions have a greater accuracy than the 80/20. We would have expected them to be lower, since 80/20 receives more training. This could be because the extra instances used in training are noisier, slightly hurting the model's performance (in the case of 80/20)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c8da6",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "Cross validation will allow us to further evaluate how a model performs on this dataset.\n",
    "\n",
    "A random forest model with default parameters (besides `random_state`) will be used in a 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4c351a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracy: 96.63%\n"
     ]
    }
   ],
   "source": [
    "def cross_val():\n",
    "    # Model and KFold model\n",
    "    exp_model = RandomForestClassifier(random_state=r_state)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=r_state)\n",
    "    \n",
    "    # Calculate scores\n",
    "    scores = cross_val_score(exp_model, X, Y, cv=cv, scoring='accuracy')\n",
    "    return np.mean(scores)\n",
    "\n",
    "scores = cross_val()\n",
    "print(f'Cross validation accuracy: {round(scores*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34979a2",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The models in all tests consistently produce high results of +93% accuracy and by varying some factors the model achieved close to 97%. This clearly shows how well the models learn the dataset. The cross validation also suggests that any new data (such as new characters of other alphabets) would be learned accurately as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4a43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "David Graham (1911734)"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
